{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SS7nfICxgkWu"
      },
      "source": [
        "# Natural Language Processing 2024 â€“ Ex. 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hq8U8nL8yfH6"
      },
      "source": [
        "**Add the names and ID of the submitting students here:**\n",
        "\n",
        "1. Yaniv Gabay - 205745615 - yanivga@edu.hac.ac.il\n",
        "\n",
        "\n",
        "2. Shahar Asher - 209305408 - shaharas@edu.hac.ac.il\n",
        "\n",
        "\n",
        "3. Hadar Liel Harush - 211721568 - hadarhar@edu.hac.ac.il"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xLnhXF3ok9Cd"
      },
      "source": [
        "\n",
        "In this exercise we will perform the task of Sentiment analysis over the IMDB movie review dataset.\n",
        "\n",
        "The dataset has around 50K movie reviews with each review labeled as \"positive\" or \"negative\".\n",
        "\n",
        "Our goal is given the review we want to classifiy it as positive or negative, this task is also called \"Sentiment Analysis\"\n",
        "\n",
        "Below you can find a suggestion of the order things should be implemented, you can follow this or do it your own way.\n",
        "\n",
        "The exercise has several stages:\n",
        "\n",
        "1. Downloading and cleaning the data\n",
        "2. Running some basic analysis\n",
        "3. Training a Feed Forward network to perform the task using classification\n",
        "4. Training a Bi-Dir LSTM to perform the task\n",
        "5. Playing with paramters to see if we get better results\n",
        "\n",
        "Please sumbit the notebook after it's running stage. Grade will be given for clean code, with comments and explanations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IPKFv5SrsO4f",
        "outputId": "dad40500-ae83-42a4-e624-cc2d0f2b6ad7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: contractions in /usr/local/lib/python3.10/dist-packages (0.1.73)\n",
            "Requirement already satisfied: textsearch>=0.0.21 in /usr/local/lib/python3.10/dist-packages (from contractions) (0.0.24)\n",
            "Requirement already satisfied: anyascii in /usr/local/lib/python3.10/dist-packages (from textsearch>=0.0.21->contractions) (0.3.2)\n",
            "Requirement already satisfied: pyahocorasick in /usr/local/lib/python3.10/dist-packages (from textsearch>=0.0.21->contractions) (2.0.0)\n",
            "Requirement already satisfied: afinn in /usr/local/lib/python3.10/dist-packages (0.1)\n",
            "cpu\n",
            "False\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "import nltk\n",
        "import pandas as pd\n",
        "from IPython.display import display\n",
        "import re\n",
        "!pip install contractions\n",
        "!pip install afinn\n",
        "import contractions\n",
        "from afinn import Afinn\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "import torch\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)\n",
        "print(torch.cuda.is_available())\n",
        "nltk.download('stopwords')\n",
        "\n",
        "#from google.colab import files\n",
        "#import io"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Dictionary to store uploaded files\n",
        "# uploaded_file = files.upload()"
      ],
      "metadata": {
        "id": "7V_6aifJyFgE"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "-BW_axSuzup4"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4QfMknbomReU"
      },
      "source": [
        "# Data download and cleaning\n",
        "\n",
        "1. Download the IMDB dataset.\n",
        "\n",
        "2. Clean the data:\n",
        "* Remove URLs, HTML tags and non-alphanumeric characters\n",
        "* Remove stop-words (use NLTK)\n",
        "* Lowercase the dataset\n",
        "* (Optional) Anything else you think can help...\n",
        "\n",
        "Show one example of a review before and after this cleaning (find a review which has at least one URL/HTML tag/Non-aplhanumeric characters)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 655
        },
        "id": "h9PUr7Mtk7s8",
        "outputId": "fb82df15-4eb0-4bdd-c402-805c6bc5fd43"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original: This is an example review with HTML <b>bold</b> tags and a URL: https://example.com\n",
            "Cleaned: example review html bold tags url\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                                              review sentiment\n",
              "0  One of the other reviewers has mentioned that ...  positive\n",
              "1  A wonderful little production. <br /><br />The...  positive\n",
              "2  I thought this was a wonderful way to spend ti...  positive\n",
              "3  Basically there's a family where a little boy ...  negative\n",
              "4  Petter Mattei's \"Love in the Time of Money\" is...  positive"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0713001e-59dc-4cad-9d4b-ef181515c6b5\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>One of the other reviewers has mentioned that ...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I thought this was a wonderful way to spend ti...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Basically there's a family where a little boy ...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0713001e-59dc-4cad-9d4b-ef181515c6b5')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-0713001e-59dc-4cad-9d4b-ef181515c6b5 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-0713001e-59dc-4cad-9d4b-ef181515c6b5');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-92564eb3-0aee-4c6e-a1c1-a844bd76a1c9\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-92564eb3-0aee-4c6e-a1c1-a844bd76a1c9')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-92564eb3-0aee-4c6e-a1c1-a844bd76a1c9 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cleaned text printing:\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                                              review sentiment\n",
              "0  one reviewers mentioned watching DIGPLACHOLD o...  positive\n",
              "1  wonderful little production filming technique ...  positive\n",
              "2  thought wonderful way spend time hot summer we...  positive\n",
              "3  basically family little boy jake thinks zombie...  negative\n",
              "4  petter mattei love time money visually stunnin...  positive"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8f954056-e4cb-40e9-9333-272bf6aff49a\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>one reviewers mentioned watching DIGPLACHOLD o...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>wonderful little production filming technique ...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>thought wonderful way spend time hot summer we...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>basically family little boy jake thinks zombie...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>petter mattei love time money visually stunnin...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8f954056-e4cb-40e9-9333-272bf6aff49a')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-8f954056-e4cb-40e9-9333-272bf6aff49a button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-8f954056-e4cb-40e9-9333-272bf6aff49a');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-425fcaa6-dd88-49c1-8964-f28793141457\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-425fcaa6-dd88-49c1-8964-f28793141457')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-425fcaa6-dd88-49c1-8964-f28793141457 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "45613    hilarious insightful perspective dating world ...\n",
            "42474    overlong compelling retelling friendship civil...\n",
            "20438    warning possible spoilers rock star one solid ...\n",
            "10220    man funniest movie ever seen laughed hard cryi...\n",
            "36129    though us sexiness variable quality cannot rec...\n",
            "26793    destroy planets winds settling destroy tokyo f...\n",
            "18953    everyone decent job film agree comment loose s...\n",
            "26521    saw movie recently really liked surprised crie...\n",
            "15223    hokey movie left groaning exchange dialogue pl...\n",
            "10264    pretty disappointing prequel first two films g...\n",
            "Name: review, dtype: object\n"
          ]
        }
      ],
      "source": [
        "# we tried to spell correct the data but the results very not good\n",
        "# so we decided to not use it example \"muslims\" into \"musea\"\n",
        "\n",
        "#another decision,is when removing stopword, to exlude all sentiment related words.\n",
        "#after searching for a reasonable solution, we found AFINN sentiment analysis\n",
        "\n",
        "#afinn object\n",
        "afinn = Afinn()\n",
        "\n",
        "digitplaceholder = 'DIGPLACHOLD' # <DIGIT>\n",
        "\n",
        "\n",
        "\n",
        "#created a function to export the data\n",
        "#so we can eaisly observe the data manually.\n",
        "#sometimes, best to observe the data manually.\n",
        "def export_curr_data_to_csv(num_of_question,df):\n",
        "    try:\n",
        "         output_file = \"curr_data\"+num_of_question+\".csv\"\n",
        "         df.to_csv(output_file, index=False)\n",
        "         return\n",
        "    except Exception as e:\n",
        "          print(\"Error loading data: {}\".format(e))\n",
        "          exit(1)\n",
        "\n",
        "#basic cleaning function\n",
        "# need to drop the html tags, urls, non-alphanumeric characters, convert to lowercase, remove stopwords, turn digits into token\n",
        "          # TO ADD: sentiment related stopwords, like not , should be kept.\n",
        "def clean_text(text):\n",
        "    #1 Remove HTML tags\n",
        "    text = re.sub(r'<.*?>', '', text)\n",
        "    #2 Remove URLs\n",
        "    text = re.sub(r'http\\S+', '', text)\n",
        "    #3 Remove non-alphanumeric characters\n",
        "    text = re.sub(r'\\W', ' ', text)\n",
        "\n",
        "\n",
        "    #4 Convert to lowercase\n",
        "    text = text.lower()\n",
        "\n",
        "\n",
        "\n",
        "    # Replace non-ASCII characters\n",
        "    #after finding out there were several non-ascii chars\n",
        "    text = re.sub(r'[^\\x00-\\x7F]+', '', text)\n",
        "    words = text.split()\n",
        "\n",
        "    #5 Remove stopwords\n",
        "    #set of stop words\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "\n",
        "    #every stop word, which has sentiment of 0, will be removed\n",
        "    #we can even try to remove -1 and +1 cause of weak sentiment\n",
        "    #check those print statments to see how it works:\n",
        "    #print(\"not value:\"+str(afinn.score('not')))\n",
        "    #print(\"bad value:\"+str(afinn.score('bad')))\n",
        "    #print(\"horrible value:\"+str(afinn.score('horrible')))\n",
        "    #print(\"lion value:\"+str(afinn.score('lion')))\n",
        "    sentiment_stop_words = {word for word in stop_words if afinn.score(word) != 0}\n",
        "\n",
        "    #STILL WORDS like NOT which affect sentiment\n",
        "    # are removed, we can try to keep them, using a list of commong sentiment words\n",
        "    #and removing that from stopwords\n",
        "    stop_words = stop_words - sentiment_stop_words - {'not','no','nor','neither','never','none','nobody','nothing','nowhere'}\n",
        "    text = ' '.join([word for word in words if word not in stop_words])\n",
        "    #6 turn Digits into Token\n",
        "\n",
        "    #3rd,8th etc. will be replaced with ALPHANUM\n",
        "    pattern = r'\\b(?:\\d+[a-zA-Z]|[a-zA-Z]+\\d)[a-zA-Z\\d]*\\b'\n",
        "    placeholder = 'ALPHANUM'\n",
        "    text = re.sub(pattern, placeholder, text)\n",
        "    text = re.sub(r'\\d+', digitplaceholder, text)\n",
        "    #need to decide what to do with 3rd, 4th  etc.\n",
        "    # as this moment 3rd will turn into DIGPLACHOLDrd, which is not good.\n",
        "    #7 additional steps if needed\n",
        "\n",
        "    return text\n",
        "def load_text(filename):\n",
        "   file_path = filename\n",
        "   #IMDB data set has header at 0 row\n",
        "   data = pd.read_csv(file_path, header=0, names=['review', 'sentiment'])\n",
        "   display(data.head())\n",
        "\n",
        "\n",
        "    # Apply the cleaning function to the review column\n",
        "   data['review'] = data['review'].apply(clean_text)\n",
        "   return data\n",
        "\n",
        "# Example usage\n",
        "example_review = \"This is an example review with HTML <b>bold</b> tags and a URL: https://example.com\"\n",
        "cleaned_review = clean_text(example_review)\n",
        "print(\"Original:\", example_review)\n",
        "print(\"Cleaned:\", cleaned_review)\n",
        "try:\n",
        "# Load the data\n",
        "    data = load_text('./IMDB Dataset.csv')\n",
        "    data_orig_copy = data.copy()\n",
        "    print(\"cleaned text printing:\\n\")\n",
        "    display(data.head())\n",
        "    print(data.sample(10)['review'])\n",
        "    #export_curr_data_to_csv(\"1\",data)\n",
        "   # describe = data.describe()\n",
        "   # print(describe)\n",
        "\n",
        "\n",
        "except Exception as e:\n",
        "    print(\"Error loading data: {}\".format(e))\n",
        "    exit(1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yIVRS_efnIWM"
      },
      "source": [
        "# Tokenization\n",
        "\n",
        "1. Tokenize the dataset (you can tokenize using spaces or use more robust methods from NLTK)\n",
        "2. (Optional) Lemmatize the text (you can use NLTK) this can improve results\n",
        "3. Lemmatize should be carfully be done, so we wont lose too much.\n",
        "4. Show an example of 3 sentences before and after this process"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AdlCQ--gnwYh",
        "outputId": "06af62ba-2b3e-4052-c23d-9dcac2922afd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.Original: The cats are chasing the mice.\n",
            "1.Cleaned: cats chasing mice\n",
            "2.Expanded: cats chasing mice\n",
            "3.Processed: cat chase mouse \n",
            "\n",
            "0.Original: He was running late for the meeting.\n",
            "1.Cleaned: running late meeting\n",
            "2.Expanded: running late meeting\n",
            "3.Processed: run late meeting \n",
            "\n",
            "0.Original: She's not enjoying the sunny weather.\n",
            "1.Cleaned: not enjoying sunny weather\n",
            "2.Expanded: not enjoying sunny weather\n",
            "3.Processed: not enjoy sunny weather \n",
            "\n",
            "0.Original: I didnt like that movie at all, very bad\n",
            "1.Cleaned: didnt like movie bad\n",
            "2.Expanded: did not like movie bad\n",
            "3.Processed: did not like movie bad \n",
            "\n",
            "0.Original: despite the fact that the movie was bad, i still enjoyed it\n",
            "1.Cleaned: despite fact movie bad still enjoyed\n",
            "2.Expanded: despite fact movie bad still enjoyed\n",
            "3.Processed: despite fact movie bad still enjoy \n",
            "\n"
          ]
        }
      ],
      "source": [
        "from nltk.corpus import wordnet\n",
        "from nltk.tag import pos_tag\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "\n",
        "#we decided to use POS tagging\n",
        "\n",
        "\n",
        "\n",
        "# contractions do:\n",
        "#will make she's into she is\n",
        "def expand_text_contractions(text):\n",
        "    expanded_text = contractions.fix(text)\n",
        "    return expanded_text\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# this prevent the lemmatize process from taking\n",
        "# words like was and convert them into \"wa\"\n",
        "auxiliary_verbs = {\"am\", \"is\", \"are\", \"was\", \"were\", \"be\", \"being\", \"been\", \"will\", \"shall\", \"would\", \"should\", \"can\", \"could\", \"may\", \"might\", \"must\", \"do\", \"does\", \"did\", \"have\", \"has\", \"had\"}\n",
        "\n",
        "def get_wordnet_pos(treebank_tag):\n",
        "    \"\"\"Map POS tag to the format accepted by WordNetLemmatizer.\"\"\"\n",
        "    tag_dict = {\n",
        "        'J': wordnet.ADJ,\n",
        "        'N': wordnet.NOUN,\n",
        "        'V': wordnet.VERB,\n",
        "        'R': wordnet.ADV\n",
        "    }\n",
        "    return tag_dict.get(treebank_tag[0].upper(), wordnet.NOUN)\n",
        "def tokenize_and_lemmatize(text):\n",
        "\n",
        "    tokens = word_tokenize(text)\n",
        "    pos_tags = nltk.pos_tag(tokens)\n",
        "    #print(\"POS Tags:\", pos_tags)\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    lemmatized_tokens = []\n",
        "    for token, pos in pos_tags:\n",
        "        # Skip lemmatization for auxiliary verbs\n",
        "        #from our expereince we saw that the lemmatize function\n",
        "        #converts words like was into wa\n",
        "        #and in general didnt handle aux verbs well\n",
        "        if token in auxiliary_verbs:\n",
        "\n",
        "            lemmatized_tokens.append(token)\n",
        "        else:\n",
        "\n",
        "            lemma = lemmatizer.lemmatize(token, get_wordnet_pos(pos))\n",
        "            lemmatized_tokens.append(lemma)\n",
        "\n",
        "    return ' '.join(lemmatized_tokens)\n",
        "\n",
        "\n",
        "\n",
        "# Example sentences\n",
        "example_sentences = [\n",
        "    \"The cats are chasing the mice.\",\n",
        "    \"He was running late for the meeting.\",\n",
        "    \"She's not enjoying the sunny weather.\",\n",
        "    \"I didnt like that movie at all, very bad\",\n",
        "    \"despite the fact that the movie was bad, i still enjoyed it\"\n",
        "]\n",
        "\n",
        "\n",
        "# Process and display the examples\n",
        "for sentence in example_sentences:\n",
        "    cleaned_text = clean_text(sentence)\n",
        "    expanded_sentence = expand_text_contractions(cleaned_text)\n",
        "\n",
        "    processed = tokenize_and_lemmatize(expanded_sentence)\n",
        "    print(\"0.Original:\", sentence)\n",
        "    print(\"1.Cleaned:\", cleaned_text)\n",
        "    print(\"2.Expanded:\", expanded_sentence)\n",
        "    print(\"3.Processed:\", processed, \"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uls-qLAcoT2Z"
      },
      "source": [
        "# Basic analysis\n",
        "\n",
        "Perfrom some analysis on the data\n",
        "1. Show the number percentage of negative/positive review (label balancing)\n",
        "2. Plot some statistics on the length of review (after our cleaning process)\n",
        "3. (Optional) show anything else you think is important"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "id": "jnpnbjXcoRJx",
        "outputId": "d64eb053-9ef3-4740-df38-d9e8fa18af8f"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-68a08f0b1489>\u001b[0m in \u001b[0;36m<cell line: 14>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m#we wanted to maybe play with both results, and see how good\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m#tokenize_and_lemmatize and expand_text_contractions are.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'processed_review'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'review'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfinal_preprocess\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m#data right now is :\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, convert_dtype, args, **kwargs)\u001b[0m\n\u001b[1;32m   4769\u001b[0m         \u001b[0mdtype\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfloat64\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4770\u001b[0m         \"\"\"\n\u001b[0;32m-> 4771\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mSeriesApply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert_dtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4772\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4773\u001b[0m     def _reduce(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m         \u001b[0;31m# self.f is Callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1123\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1125\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0magg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1172\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1173\u001b[0m                 \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1174\u001b[0;31m                 mapped = lib.map_infer(\n\u001b[0m\u001b[1;32m   1175\u001b[0m                     \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1176\u001b[0m                     \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m<ipython-input-7-68a08f0b1489>\u001b[0m in \u001b[0;36mfinal_preprocess\u001b[0;34m(review)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mafter_contractions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexpand_text_contractions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreview\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;31m# Then, tokenize and lemmatize the expanded review\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mprocessed_review\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenize_and_lemmatize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mafter_contractions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mprocessed_review\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-6-d1f186949f34>\u001b[0m in \u001b[0;36mtokenize_and_lemmatize\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0mtokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mword_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m     \u001b[0mpos_tags\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpos_tag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m     \u001b[0;31m#print(\"POS Tags:\", pos_tags)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0mlemmatizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mWordNetLemmatizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/nltk/tag/__init__.py\u001b[0m in \u001b[0;36mpos_tag\u001b[0;34m(tokens, tagset, lang)\u001b[0m\n\u001b[1;32m    164\u001b[0m     \"\"\"\n\u001b[1;32m    165\u001b[0m     \u001b[0mtagger\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_tagger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlang\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_pos_tag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtagset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtagger\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlang\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/nltk/tag/__init__.py\u001b[0m in \u001b[0;36m_pos_tag\u001b[0;34m(tokens, tagset, tagger, lang)\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m         \u001b[0mtagged_tokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtagger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtagset\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Maps to the specified tagset.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlang\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"eng\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/nltk/tag/perceptron.py\u001b[0m in \u001b[0;36mtag\u001b[0;34m(self, tokens, return_conf, use_tagdict)\u001b[0m\n\u001b[1;32m    185\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtag\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m                 \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprev\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprev2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m                 \u001b[0mtag\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_conf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m             \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtag\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconf\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mreturn_conf\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;32mTrue\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/nltk/tag/perceptron.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, features, return_conf)\u001b[0m\n\u001b[1;32m     64\u001b[0m             \u001b[0mweights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeat\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m                 \u001b[0mscores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0;31m# Do a secondary alphabetic sort, for stability\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "#beware long run time\n",
        "# 6-7 min run time (POS tagging takes time)\n",
        "def final_preprocess(review):\n",
        "    # First, expand contractions\n",
        "    after_contractions = expand_text_contractions(review)\n",
        "    # Then, tokenize and lemmatize the expanded review\n",
        "    processed_review = tokenize_and_lemmatize(after_contractions)\n",
        "    return processed_review\n",
        "\n",
        "# Apply the preprocess_review function to each review in the DataFrame\n",
        "#we created another col here, instead of rewriting the data.\n",
        "#we wanted to maybe play with both results, and see how good\n",
        "#tokenize_and_lemmatize and expand_text_contractions are.\n",
        "data['processed_review'] = data['review'].apply(final_preprocess)\n",
        "\n",
        "#data right now is :\n",
        "#1.review |2. sentiment |3. processed_review\n",
        "#:\n",
        "#1.review - is after preprocessing\n",
        "#2.sentiment - is the original data (havent changed)\n",
        "#3.processed_review - is after clean and final preprocess so proccesed.\n",
        "\n",
        "# Display the first few rows to verify the changes\n",
        "print(data[['review', 'processed_review']].head())\n",
        "#export_curr_data_to_csv(\"3\",data)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oskUdfwqsO4k"
      },
      "outputs": [],
      "source": [
        "##### label balancing\n",
        "label_counts = data_orig_copy['sentiment'].value_counts(normalize=True) * 100\n",
        "print(label_counts)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gC1Q9fjCsO4l"
      },
      "outputs": [],
      "source": [
        "# Calculating the length of each cleaned review\n",
        "data['review_length'] = data['processed_review'].apply(len)\n",
        "export_curr_data_to_csv(\"4\",data)\n",
        "data_orig_copy['review_length'] = data_orig_copy['review'].apply(len)\n",
        "# Displaying basic statistics\n",
        "print(\"Statistics on the length of cleaned reviews:\")\n",
        "print(data['review_length'].describe())\n",
        "print(data_orig_copy['review_length'].describe())\n",
        "\n",
        "\n",
        "def calculate_review_statistics(review_lengths):\n",
        "    \"\"\"\n",
        "    Calculate and return a dictionary of statistics for a given Series of review lengths.\n",
        "    \"\"\"\n",
        "    return {\n",
        "        'mean_length': review_lengths.mean(),\n",
        "        'median_length': review_lengths.median(),\n",
        "        'q1': review_lengths.quantile(0.25),\n",
        "        'q3': review_lengths.quantile(0.75),\n",
        "        'min_length': review_lengths.min(),\n",
        "        'max_length': review_lengths.max(),\n",
        "    }\n",
        "\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "processed_review_stats = calculate_review_statistics(data['review_length'])\n",
        "\n",
        "original_review_stats = calculate_review_statistics(data_orig_copy['review_length'])\n",
        "\n",
        "\n",
        "\n",
        "def plot_review_statistics(review_lengths, stats, title):\n",
        "    fig, ax = plt.subplots(nrows=1,ncols=1, figsize=(9, 7))\n",
        "    bp = ax.boxplot(review_lengths, vert=True, patch_artist=True, showmeans=True, meanline=True, showfliers=True, showcaps=True,flierprops=dict(marker='o', markerfacecolor='red',markeredgecolor='black', markersize=12, linestyle='none'))\n",
        "\n",
        "    # Customizing the boxplot appearance\n",
        "    bp['boxes'][0].set_facecolor('lightblue')\n",
        "\n",
        "    ax.grid(True, which='both', linestyle='-', linewidth=0.2)\n",
        "\n",
        "    # Setting the x-axis limit to make room for annotations\n",
        "    ax.set_xlim(0, 1.25)\n",
        "\n",
        "    # Annotating statistics\n",
        "    stat_y_base = max(review_lengths)  # Start annotations at the top\n",
        "    y_offset = (max(review_lengths) - min(review_lengths)) * 0.03  # Space between annotations\n",
        "\n",
        "    legend_labels = []\n",
        "    for i, (stat_name, stat_value) in enumerate(stats.items()):\n",
        "        legend_labels.append(f'{stat_name}: {stat_value:.2f}')\n",
        "\n",
        "    # Finalizing the plot\n",
        "    ax.set_title(title)\n",
        "    ax.set_ylabel('Review Length')\n",
        "    ax.set_xticklabels(['Reviews'])  # Adjust tick label as needed\n",
        "    ax.set_xlabel('Review Type')\n",
        "    #ax.grid(True, which='both', linestyle='--', linewidth=0.5)\n",
        "    #ax.legend(legend_labels, loc='upper left', fontsize='small', shadow=True, fancybox=True, title='Statistics')\n",
        "    for i, label in enumerate(legend_labels):\n",
        "        ax.text(0.02, 0.95 - i * 0.05, label, transform=plt.gca().transAxes, fontsize='small')\n",
        "\n",
        "    plt.show()\n",
        "    return fig, ax\n",
        "\n",
        "# Plot them separately\n",
        "plot_review_statistics(data['review_length'], processed_review_stats, 'Processed Reviews Statistics')\n",
        "plot_review_statistics(data_orig_copy['review_length'], original_review_stats, 'Original Reviews Statistics')\n",
        "\n",
        "\n",
        "#graph to show both of them using seaborn\n",
        "# Create a new DataFrame for plotting\n",
        "!pip install seaborn\n",
        "import seaborn as sns\n",
        "length_comparison = pd.DataFrame({\n",
        "    \"Length\": pd.concat([data['review_length'], data_orig_copy['review_length']]),\n",
        "    \"Type\": [\"Processed\"] * len(data) + [\"Original\"] * len(data_orig_copy)\n",
        "})\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "plt.figure(figsize=(12, 8))\n",
        "sns.boxplot(x='Type', y='Length', data=length_comparison, whis=1.5, width=0.2)\n",
        "plt.title('Comparison of Review Lengths: Original vs Processed')\n",
        "plt.ylabel('Review Length')\n",
        "plt.xlabel('Review Type')\n",
        "plt.show()\n",
        "\n",
        "##### we can show the pos tags of the words in a graph or as stats\n",
        "##### as a cake!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I-b0Fu9vqocP"
      },
      "source": [
        "# Preparing the dataset for training\n",
        "we can also use glove or previously used models as the first layer\n",
        "1. Choose your vocabulary size K (should be between 1000 and 3000)\n",
        "2. Find the top K frequent words in your database\n",
        "3. Create word indexes like we did in class, for any word not in your top K  words replace with \\<UNK\\>. Remember to add an index for the \\<PAD\\> token.\n",
        "4. Create a new dataset with indexes instead of words later to be used for training\n",
        "5. Convert your labels to numeric representation (that your network can deal with).\n",
        "\n",
        "Split the dataset to 80% traind and 20% test, remember to keep the balance between labels!\n",
        "we need to make sure, we still have enough labels on both sides\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZawXFmEHqnvA"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "# Make sure, the preprocessed data is data['processed_review']\n",
        "from collections import Counter\n",
        "\n",
        "#vocabulary side\n",
        "K = 3000\n",
        "\n",
        "all_tokens = [token for sublist in data['processed_review'].str.split().tolist() for token in sublist]\n",
        "\n",
        "token_counts = Counter(all_tokens)\n",
        "\n",
        "vocab = {word for word, count in token_counts.most_common(K)}\n",
        "print(vocab)\n",
        "#if digitplaceholder in vocab:\n",
        "   # print(\"Digit placeholder found in vocabulary!\")\n",
        "\n",
        "word_to_index = {word: idx + 3 for idx, word in enumerate(vocab)}\n",
        "word_to_index[digitplaceholder] = 2 # Start from 2 to reserve indices for special tokens\n",
        "word_to_index['<UNK>'] = 1  # Unknown words\n",
        "word_to_index['<PAD>'] = 0  # Padding\n",
        "\n",
        "def text_to_sequence(text):\n",
        "    return [word_to_index.get(word, word_to_index['<UNK>']) for word in text.split()]\n",
        "\n",
        "data['indexed_text'] = data['processed_review'].apply(text_to_sequence)\n",
        "print(data['indexed_text'].head())\n",
        "\n",
        "#hello world <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>.... 500\n",
        "\n",
        "def pad_sequences(sequences, maxlen):\n",
        "    padded_sequences = []\n",
        "    for seq in sequences:\n",
        "        if len(seq) < maxlen:\n",
        "            seq += [word_to_index['<PAD>']] * (maxlen - len(seq))\n",
        "        else:\n",
        "            seq = seq[:maxlen]\n",
        "        padded_sequences.append(seq)\n",
        "    return padded_sequences\n",
        "\n",
        "maxlen = 500  # Choose a suitable maximum sequence length\n",
        "data['padded_sequences'] = pad_sequences(data['indexed_text'].tolist(), maxlen)\n",
        "print(data['padded_sequences'].head())\n",
        "#export_curr_data_to_csv(\"5\",data)\n",
        "for i, seq in enumerate(data['padded_sequences'].head()):\n",
        "    print(f\"Sequence {i+1}: Length = {len(seq)}\")\n",
        "    #print(seq)\n",
        "    print(\"\\n\")\n",
        "#splitting test and train\n",
        "#using sklearn model selection, we can split the data into test and train\n",
        "#and give a paramater to maintain the same distribution of labels\n",
        "\n",
        "#first numerate the sentiment col\n",
        "# Convert sentiment labels from 'positive'/'negative' to 1/0\n",
        "data['numeric_sentiment'] = data['sentiment'].map({'positive': 1, 'negative': 0})\n",
        "\n",
        "features = data['padded_sequences'].tolist()\n",
        "labels = data['numeric_sentiment'].tolist()\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.2, stratify=labels, random_state=42)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8UokkSJLp5VQ"
      },
      "source": [
        "# Training a feed forward neural network\n",
        "\n",
        "For simplicity we would take only reviews with 500 words (after tokenization) or less.\n",
        "For this part we would train a neural network that gets the full review as one input (like we had in our NER example in class) and outputs the label (positive or negative).\n",
        "Remember that you need to PAD the words so all reviews will have the same length.\n",
        "\n",
        "For this section please try at least 3 variants of different network and show if the results change, you can choose from the following:\n",
        "1. Adding hidden layers to the network\n",
        "2. Running with and without Dropout\n",
        "3. Trying different optimizers\n",
        "\n",
        "(Optional) Try to use the Glove embedding: Create an embedding layer in your PyTorch model using the loaded GloVe embeddings. You will initialize the weights of the embedding layer with the GloVe embeddings.\n",
        "\n",
        "For each option:\n",
        "\n",
        "* Plot the train and test error during training, does your network overfit?\n",
        "\n",
        "* Plot the final results of the network, including accuracy and confusion matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NFtHmXUKp4hI"
      },
      "outputs": [],
      "source": [
        "!pip install torch\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "def build_model(vocab_size, embedding_dim, hidden_dims, output_dim, dropout, use_glove=False, glove_weights=None, freeze_embedding=True):\n",
        "    class CustomSentimentClassifier(nn.Module):\n",
        "        def __init__(self):\n",
        "            super(CustomSentimentClassifier, self).__init__()\n",
        "            self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "            if use_glove:\n",
        "                self.embedding.weight.data.copy_(torch.from_numpy(glove_weights))\n",
        "                self.embedding.weight.requires_grad = False\n",
        "                if not freeze_embedding:\n",
        "                    self.embedding.weight.requires_grad = True\n",
        "            self.layers = nn.ModuleList()\n",
        "            for i in range(len(hidden_dims)):\n",
        "                input_dim = embedding_dim if i == 0 else hidden_dims[i-1]\n",
        "                self.layers.append(nn.Linear(input_dim, hidden_dims[i]))\n",
        "                self.layers.append(nn.ReLU())\n",
        "                if dropout > 0:\n",
        "                    self.layers.append(nn.Dropout(dropout))\n",
        "            self.layers.append(nn.Linear(hidden_dims[-1], output_dim))\n",
        "\n",
        "        def forward(self, text):\n",
        "            embedded = self.embedding(text)\n",
        "            output = embedded.mean(dim=1)\n",
        "            for layer in self.layers:\n",
        "                output = layer(output)\n",
        "            return output\n",
        "\n",
        "    return CustomSentimentClassifier()\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)\n",
        "\n",
        "train_data = TensorDataset(torch.from_numpy(np.array(X_train)), torch.from_numpy(np.array(y_train)))\n",
        "test_data = TensorDataset(torch.from_numpy(np.array(X_test)), torch.from_numpy(np.array(y_test)))\n",
        "\n",
        "batch_size = 64  # You can adjust this based on your GPU memory\n",
        "\n",
        "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(test_data, batch_size=batch_size)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hcoqydlSsO4o"
      },
      "outputs": [],
      "source": [
        "vocab_size = K + 3  # Your top K words plus 3 for <PAD>, <UNK>, and digitplaceholder\n",
        "embedding_dim = 100  # Example, adjust as needed\n",
        "num_epochs = 15  # Adjust based on your needs\n",
        "output_dim = 1  # Binary classification\n",
        "\n",
        "def load_glove_embeddings(glove_file):\n",
        "    embeddings = {}\n",
        "    with open(glove_file, 'r', encoding='utf-8') as f:\n",
        "        for line in f:\n",
        "            values = line.split()\n",
        "            word = values[0]\n",
        "            vector = np.asarray(values[1:], dtype='float32')\n",
        "            embeddings[word] = vector\n",
        "    return embeddings\n",
        "\n",
        "glove_embeddings = load_glove_embeddings('./glove.6B.100d.word2vec.txt')\n",
        "\n",
        "embedding_dim = 100\n",
        "embedding_matrix = np.zeros((vocab_size, embedding_dim))\n",
        "\n",
        "for word, idx in word_to_index.items():\n",
        "    embedding_vector = glove_embeddings.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        embedding_matrix[idx] = embedding_vector  # words not found in the embedding index will be all zeros\n",
        "\n",
        "\n",
        "def create_embedding_matrix(vocab, glove_embeddings, embedding_dim):\n",
        "    # Adjust the size to accommodate special tokens\n",
        "    embedding_matrix = torch.zeros((len(vocab) + 3, embedding_dim))  # +3 for <PAD>, <UNK>, digitplaceholder\n",
        "    for word, idx in vocab.items():\n",
        "        if word in glove_embeddings:\n",
        "            embedding_matrix[idx] = torch.tensor(glove_embeddings[word])\n",
        "        else:\n",
        "            embedding_matrix[idx] = torch.randn(embedding_dim)  # Random initialization for words not in GloVe\n",
        "    return embedding_matrix\n",
        "\n",
        "\n",
        "glove_weights = create_embedding_matrix(word_to_index, glove_embeddings, embedding_dim)\n",
        "# Define device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Define loss function\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "\n",
        "# Experiment configurations\n",
        "experiment_configs = [\n",
        "    {'hidden_dims': [128], 'dropout': 0.3, 'optimizer': 'Adam'},\n",
        "    {'hidden_dims': [128], 'dropout': 0.1, 'optimizer': 'AdaGrad '}, # big lr worst results so far\n",
        "    {'hidden_dims': [256], 'dropout': 0.2, 'optimizer': 'Adam'},\n",
        "    {'hidden_dims': [128], 'dropout': 0.7, 'optimizer': 'Adam'}, #too high drop out\n",
        "    {'hidden_dims': [128], 'dropout': 0.5, 'optimizer': 'SGD'}, # also not impressive\n",
        "    {'hidden_dims': [128], 'dropout': 0.5, 'optimizer': 'RMSprop'},\n",
        "     {'hidden_dims': [256], 'dropout': 0.3, 'optimizer': 'RMSprop'},\n",
        "      {'hidden_dims': [128], 'dropout': 0.1, 'optimizer': 'RMSprop'},\n",
        "    # Add more configurations for different experiments...\n",
        "]\n",
        "\n",
        "experiment_results = {}\n",
        "\n",
        "\n",
        "def train_and_evaluate(model,train_loader,test_loader,num_epochs,optimizer, criterion, device):\n",
        "#identifying overfitting.\n",
        "    train_losses, test_losses = [], []\n",
        "    model = model.to(device)\n",
        "\n",
        "    print(\"started training\")\n",
        "    for epoch in range(num_epochs):\n",
        "        print(f'Epoch: ' + str(epoch+1))\n",
        "        model.train()\n",
        "        batch_losses = []\n",
        "        for texts, labels in train_loader:\n",
        "            texts, labels = texts.to(device).long(), labels.to(device).float()\n",
        "            optimizer.zero_grad()\n",
        "            predictions = model(texts).squeeze(1)\n",
        "            loss = criterion(predictions, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            batch_losses.append(loss.item())\n",
        "        train_loss = np.mean(batch_losses)\n",
        "        train_losses.append(train_loss)\n",
        "        print(f'Epoch {epoch+1}/{num_epochs}, Loss: {loss.item()}')\n",
        "        # Add validation logic per epoch if desired\n",
        "        # Calculate test loss for the current epoch\n",
        "        print(\"started testing\")\n",
        "\n",
        "        model.eval()  # Set the model to evaluation mode\n",
        "        test_loss = evaluate(model, test_loader, criterion, device)\n",
        "        test_losses.append(test_loss)\n",
        "\n",
        "        print(f'Epoch {epoch+1}/{num_epochs}, Train Loss: {train_loss:.4f}, Test Loss: {test_loss:.4f}')\n",
        "    return model, train_losses, test_losses\n",
        "# Run experiments\n",
        "def evaluate(model,data_loader,criterion,device):\n",
        "    model.eval()  # Set the model to evaluation mode\n",
        "    batch_losses = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for texts, labels in data_loader:\n",
        "            texts, labels = texts.to(device).long(), labels.to(device).float()\n",
        "            predictions = model(texts).squeeze(1)\n",
        "            loss = criterion(predictions, labels)\n",
        "            batch_losses.append(loss.item())\n",
        "\n",
        "    return np.mean(batch_losses)\n",
        "\n",
        "\n",
        "# Run experiments\n",
        "for i, config in enumerate(experiment_configs):\n",
        "    print(f'Running experiment {i+1} with config: {config}')\n",
        "\n",
        "\n",
        "    #################### choose your model here####################\n",
        "\n",
        "    ##################this is the default model no glove embeddings.\n",
        "    #model = build_model(vocab_size, embedding_dim, config['hidden_dims'], output_dim, config['dropout'])\n",
        "\n",
        "    #try the glove embeddings#\n",
        "    ##################this is glove embedding, with freeze_embedding=True\n",
        "    #from my tries, worst results by 1 perecent avg on accuracy\n",
        "    #model = build_model(vocab_size, embedding_dim, config['hidden_dims'], output_dim, config['dropout'], glove_weights=glove_weights)\n",
        "\n",
        "\n",
        "    #with glove embeddings, its works great, it adapts the weights to our vocab\n",
        "    # unfreeze changes during the training\n",
        "    model = build_model(vocab_size, embedding_dim, config['hidden_dims'], output_dim, config['dropout'], glove_weights=glove_weights, freeze_embedding=False)\n",
        "\n",
        "\n",
        "\n",
        "    model = model.to(device)\n",
        "    #### can add more optimizers\n",
        "    ###### can also give LR parameters as: , lr=0.01\n",
        "    # Choose optimizer based on config\n",
        "    if config['optimizer'] == 'Adam':\n",
        "        optimizer = torch.optim.Adam(model.parameters())\n",
        "    elif config['optimizer'] == 'SGD':\n",
        "        optimizer = torch.optim.SGD(model.parameters(),lr = 0.01)\n",
        "    elif config['optimizer'] == 'AdaGrad':\n",
        "        optimizer = torch.optim.Adagrad(model.parameters())\n",
        "    elif config['optimizer'] == 'RMSprop':\n",
        "        optimizer = torch.optim.RMSprop(model.parameters(),lr = 0.01)\n",
        "\n",
        "    # Add more optimizers as needed...\n",
        "\n",
        "    trained_model, train_losses, test_losses = train_and_evaluate(model, train_loader, test_loader, num_epochs, optimizer, criterion, device)\n",
        "\n",
        "    experiment_results[f'Experiment_{i+1}'] = {\n",
        "        'model': trained_model,\n",
        "        'train_losses': train_losses,\n",
        "        'test_losses': test_losses\n",
        "    }\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NCjzduGxsO4p"
      },
      "outputs": [],
      "source": [
        "def train_and_test_res(train_losses,test_losses,experiment_name):\n",
        "    print(\"Train Losses:\", train_losses)\n",
        "    print(\"Test Losses:\", test_losses)\n",
        "    print(f\"Number of training loss entries: {len(train_losses)}\")\n",
        "    print(f\"Number of testing loss entries: {len(test_losses)}\")\n",
        "    plt.style.use('ggplot')\n",
        "    plt.plot(train_losses, label='Training Loss', color='blue')\n",
        "    plt.plot(test_losses, label='Testing Loss', color='red')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.title(f'Training and Testing Loss Over Epochs - {experiment_name}', fontsize=16)\n",
        "    plt.legend(labelcolor='linecolor')\n",
        "    plt.grid(True)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "for experiment, result in experiment_results.items():\n",
        "    train_and_test_res(result['train_losses'], result['test_losses'], experiment)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3w08eCv3sO4p"
      },
      "outputs": [],
      "source": [
        "\n",
        "def plot_confusion_matrix(model, data_loader, device, class_names):\n",
        "    model.eval()  # Set the model to evaluation mode\n",
        "    all_predictions = []\n",
        "    all_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for texts, labels in data_loader:\n",
        "            texts = texts.to(device).long()\n",
        "            labels = labels.to(device).float()\n",
        "            predictions = model(texts).squeeze(1)\n",
        "            predicted_labels = torch.round(torch.sigmoid(predictions))\n",
        "            all_predictions.extend(predicted_labels.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    cm = confusion_matrix(all_labels, all_predictions)\n",
        "    accuracy = accuracy_score(all_labels, all_predictions)\n",
        "    print(f'Accuracy: {accuracy:.4f}')\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(8, 6))\n",
        "    cax = ax.matshow(cm, cmap='Blues')\n",
        "    plt.title('Confusion Matrix')\n",
        "    fig.colorbar(cax)\n",
        "    # Set tick positions\n",
        "    ax.set_xticks(np.arange(len(class_names)))\n",
        "    ax.set_yticks(np.arange(len(class_names)))\n",
        "    # Set tick labels\n",
        "    ax.set_xticklabels(class_names)\n",
        "    ax.set_yticklabels(class_names)\n",
        "\n",
        "    # Rotate the tick labels for x-axis\n",
        "    plt.xticks(rotation=90)\n",
        "\n",
        "    for (i, j), val in np.ndenumerate(cm):\n",
        "        ax.text(j, i, f'{val}', ha='center', va='center', color='red')\n",
        "\n",
        "    plt.xlabel('Predicted')\n",
        "    plt.ylabel('True')\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "class_names = ['Negative', 'Positive']  # Adjust as per your labels\n",
        "\n",
        "for experiment_name, experiment_result in experiment_results.items():\n",
        "    print(f\"Results for {experiment_name}:\")\n",
        "    trained_model = experiment_result['model']\n",
        "    plot_confusion_matrix(trained_model, test_loader, device, class_names)\n",
        "\n",
        "# we havnt able to reach above 88 % accuracy."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qoY1QnIdtCk3"
      },
      "source": [
        "# Training a BiDir LSTM neural network\n",
        "\n",
        "Now do the same as the prvious section with a bi-directional LSTM.\n",
        "\n",
        "Remember that the output of the LSTM should be connected to a small feed forward network to perform the actual classification.\n",
        "\n",
        "Here again you can play with number of layers and the LSTM or the small network of the output. Show only the best result you got.\n",
        "\n",
        "* Plot the train and test error during training, does your network overfit?\n",
        "\n",
        "* Plot the final results of the network, including accuracy and confusion matrix\n",
        "\n",
        "Are the results better than the previous section?\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f9WyUlmps5sO"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.utils.rnn as rnn_utils\n",
        "import random\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch\n",
        "\n",
        "\n",
        "class TextDataset(Dataset):\n",
        "    def __init__(self, sequences, labels):\n",
        "        self.sequences = sequences\n",
        "        self.labels = labels\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.sequences)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        sequence = self.sequences[idx]\n",
        "        label = self.labels[idx]\n",
        "        return torch.tensor(sequence, dtype=torch.long), torch.tensor(label, dtype=torch.float), torch.tensor(len(sequence), dtype=torch.long)\n",
        "\n",
        "def pad_collate_fn(batch):\n",
        "    batch.sort(key=lambda x: x[2], reverse=True)  # Sort by length for efficient packing\n",
        "    sequences, labels, lengths = zip(*batch)\n",
        "    sequences_padded = torch.nn.utils.rnn.pad_sequence(sequences, batch_first=True, padding_value=0)\n",
        "    return sequences_padded, torch.stack(labels), torch.stack(lengths)\n",
        "\n",
        "\n",
        "maxlen = 500  # Adjust based on your dataset analysis\n",
        "sequences = data['indexed_text'].tolist()\n",
        "#labels = data['numeric_sentiment'].tolist()\n",
        "labels = data['numeric_sentiment'].tolist()\n",
        "print(f\"Total sequences: {len(sequences)}\")\n",
        "print(f\"Total labels: {len(labels)}\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "train_sequences, test_sequences, train_labels, test_labels = train_test_split(sequences, labels, test_size=0.2, random_state=42, stratify=labels)\n",
        "\n",
        "dataset = TextDataset(sequences, labels)\n",
        "# Create TextDataset instances for both training and testing data\n",
        "train_dataset = TextDataset(train_sequences, train_labels)\n",
        "test_dataset = TextDataset(test_sequences, test_labels)\n",
        "\n",
        "# Create DataLoader instances for both training and testing datasets\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, collate_fn=pad_collate_fn)\n",
        "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False, collate_fn=pad_collate_fn)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "num_epochs = 15\n",
        "\n",
        "\n",
        "class BiLSTMClassifier(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, n_layers, dropout):\n",
        "        super(BiLSTMClassifier, self).__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, num_layers=n_layers, dropout=dropout, bidirectional=True, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_dim * 2, output_dim)  # *2 for bidirectional\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, text, text_lengths):\n",
        "        embedded = self.dropout(self.embedding(text))\n",
        "\n",
        "        packed_embedded = torch.nn.utils.rnn.pack_padded_sequence(embedded, text_lengths, batch_first=True)\n",
        "        packed_output, (hidden, _) = self.lstm(packed_embedded)\n",
        "        output, output_lengths = torch.nn.utils.rnn.pad_packed_sequence(packed_output, batch_first=True)\n",
        "        hidden = self.dropout(torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim=1))\n",
        "        return self.fc(hidden)\n",
        "\n",
        "def train_and_evaluate(model, train_loader, test_loader, num_epochs, optimizer, criterion, device):\n",
        "    model.to(device)\n",
        "    epoch_train_losses = []  # List to store average train loss per epoch\n",
        "    epoch_test_losses = []  # List to store average test loss per epoch\n",
        "\n",
        "    print(\"started training first epoch\")\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        train_losses = []\n",
        "        for sequences, labels, lengths in train_loader:\n",
        "            sequences, labels, lengths = sequences.to(device), labels.to(device),lengths\n",
        "            #print(f\"Batch Sequences Shape: {sequences.shape}\")\n",
        "            #print(f\"Batch Labels Shape: {labels.shape}\")\n",
        "            #print(f\"Batch Lengths Shape: {lengths.shape}\")\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(sequences, lengths)\n",
        "            loss = criterion(outputs.squeeze(1), labels)\n",
        "            loss.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1)\n",
        "            optimizer.step()\n",
        "\n",
        "            train_losses.append(loss.item())\n",
        "\n",
        "        avg_train_loss = sum(train_losses) / len(train_losses)\n",
        "        epoch_train_losses.append(avg_train_loss)\n",
        "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {avg_train_loss:.4f}')\n",
        "\n",
        "        # Evaluation\n",
        "        model.eval()\n",
        "        test_losses = []\n",
        "        with torch.no_grad():\n",
        "            for sequences, labels, lengths in test_loader:\n",
        "                sequences, labels, lengths = sequences.to(device), labels.to(device), lengths\n",
        "\n",
        "                outputs = model(sequences, lengths)\n",
        "                loss = criterion(outputs.squeeze(1), labels)\n",
        "\n",
        "                test_losses.append(loss.item())\n",
        "\n",
        "        avg_test_loss = sum(test_losses) / len(test_losses)\n",
        "        epoch_test_losses.append(avg_test_loss)\n",
        "        print(f'Test Loss: {avg_test_loss:.4f}')\n",
        "\n",
        "    # Return the model and the average losses for further analysis if needed\n",
        "    return model, epoch_train_losses, epoch_test_losses\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)\n",
        "n_layers = 3\n",
        "dropout = 0.4\n",
        "hidden_dim = 128\n",
        "model = BiLSTMClassifier(vocab_size, embedding_dim, hidden_dim, output_dim, n_layers, dropout)\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters())\n",
        "trained_model, train_loss, test_loss = train_and_evaluate(model, train_loader, test_loader, num_epochs, optimizer, criterion, device)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dsluvu6fLGhI"
      },
      "outputs": [],
      "source": [
        "\n",
        "def plot_confusion_matrix_bidir(model, data_loader, device, class_names):\n",
        "    model.eval()  # Set the model to evaluation mode\n",
        "    all_predictions = []\n",
        "    all_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for texts, labels, lengths in data_loader:\n",
        "            texts, lengths = texts.to(device), lengths\n",
        "            labels = labels.to(device).float()\n",
        "            predictions = model(texts, lengths).squeeze(1)\n",
        "            predicted_labels = torch.round(torch.sigmoid(predictions))\n",
        "            all_predictions.extend(predicted_labels.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    cm = confusion_matrix(all_labels, all_predictions)\n",
        "    accuracy = accuracy_score(all_labels, all_predictions)\n",
        "    print(f'Accuracy: {accuracy:.4f}')\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(8, 6))\n",
        "    cax = ax.matshow(cm, cmap='Blues')\n",
        "    plt.title('Confusion Matrix')\n",
        "    fig.colorbar(cax)\n",
        "\n",
        "    # Set ticks and labels explicitly\n",
        "    ax.set_xticks(range(len(class_names)))\n",
        "    ax.set_yticks(range(len(class_names)))\n",
        "    ax.set_xticklabels(class_names)\n",
        "    ax.set_yticklabels(class_names)\n",
        "\n",
        "    for (i, j), val in np.ndenumerate(cm):\n",
        "        ax.text(j, i, f'{val}', ha='center', va='center', color='red')\n",
        "\n",
        "    plt.xlabel('Predicted')\n",
        "    plt.ylabel('True')\n",
        "    plt.show()\n",
        "\n",
        "print(f\"Results for BiDir LSTM:\")\n",
        "\n",
        "plot_confusion_matrix_bidir(trained_model, test_loader, device, class_names)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "train_and_test_res(train_loss,test_loss, 'BiDir LSTM')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BIpmlkOdyRaS"
      },
      "source": [
        "Finally show 3 reviews from the test data with correct labales and 3 without, why do you think the network did not success on these examples?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LLdBU7zSyQZa"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "def evaluate_and_show_examples(model, test_loader, device, data):\n",
        "    model.eval()  # Set the model to evaluation mode\n",
        "    all_predictions = []\n",
        "    all_labels = []\n",
        "    all_texts = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for sequences, labels, lengths in test_loader:\n",
        "            sequences, labels, lengths = sequences.to(device), labels.to(device), lengths\n",
        "            outputs = model(sequences, lengths)\n",
        "            predicted_labels = torch.round(torch.sigmoid(outputs.squeeze(1)))\n",
        "            all_predictions.extend(predicted_labels.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "            # Collect the original texts for each sequence in the batch\n",
        "            for seq in sequences.cpu().numpy():\n",
        "                # Convert sequence back to tokens and then to text\n",
        "                text = ' '.join([data['index_to_word'][idx] for idx in seq if idx not in (0, 1, 2)])  # Assuming 0, 1, 2 are <PAD>, <UNK>, <DIGIT>\n",
        "                all_texts.append(text)\n",
        "\n",
        "    correct_examples = []\n",
        "    incorrect_examples = []\n",
        "\n",
        "    # Analyze predictions\n",
        "    for i, (pred, label, text) in enumerate(zip(all_predictions, all_labels, all_texts)):\n",
        "        if pred == label:\n",
        "            correct_examples.append((text, pred, label))\n",
        "        else:\n",
        "            incorrect_examples.append((text, pred, label))\n",
        "\n",
        "    # Randomly select 3 correct and 3 incorrect examples\n",
        "    selected_correct = random.sample(correct_examples, 3)\n",
        "    selected_incorrect = random.sample(incorrect_examples, 3)\n",
        "\n",
        "    print(\"Correctly Classified Examples:\")\n",
        "    for text, pred, label in selected_correct:\n",
        "        print(f\"Text: {text}\\nPredicted: {pred}, Actual: {label}\\n\")\n",
        "\n",
        "    print(\"\\nIncorrectly Classified Examples:\")\n",
        "    for text, pred, label in selected_incorrect:\n",
        "        print(f\"Text: {text}\\nPredicted: {pred}, Actual: {label}\\n\")\n",
        "\n",
        "# Assuming 'data' is your dataset containing the original texts and 'index_to_word' is a dictionary mapping indices back to words\n",
        "evaluate_and_show_examples(trained_model, test_loader, device, data)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " # answers\n",
        " ---\n",
        "- **Feedforward Neural Network**: The previous code utilizes a simple feedforward neural network architecture. It consists of an embedding layer followed by one or more fully connected hidden layers with ReLU activation functions. The final layer produces the output for sentiment classification.\n",
        "   - **Bidirectional LSTM**: In contrast, the latest code employs a Bidirectional Long Short-Term Memory (LSTM) neural network. This architecture includes an embedding layer, followed by a Bidirectional LSTM layer. The output of the LSTM layer is then fed into a small feedforward network for the actual classification. LSTMs are specialized recurrent neural networks capable of capturing long-term dependencies in sequential data like text.\n",
        "\n",
        "2. **Handling Sequential Data**:\n",
        "   - **Feedforward Neural Network**: Feedforward networks process input data sequentially, treating each word or token independently. They lack the ability to capture contextual information from neighboring words effectively.\n",
        "   - **Bidirectional LSTM**: LSTMs, on the other hand, are designed to handle sequential data more effectively. Bidirectional LSTMs, in particular, process input sequences in both forward and backward directions, allowing them to capture contextual information from both past and future words. This bidirectional processing is beneficial for tasks like sentiment analysis where context plays a crucial role.\n",
        "\n",
        "3. **Padding and Packing**:\n",
        "   - **Feedforward Neural Network**: In the feedforward network, padding to ensure uniform sequence lengths is not explicitly required since the model treats each input independently.\n",
        "   - **Bidirectional LSTM**: In the LSTM model, padding and packing of sequences are essential. Sequences are padded to a fixed length to ensure uniformity, and then packed to remove unnecessary padding before feeding them into the LSTM layer. This packing helps in efficient processing of variable-length sequences.\n",
        "\n",
        "4. **Training Procedure**:\n",
        "   - **Feedforward Neural Network**: Training a feedforward neural network involves standard forward and backward passes, followed by parameter updates.\n",
        "   - **Bidirectional LSTM**: Training a Bidirectional LSTM requires additional steps due to the sequential nature of the data. The sequences are sorted by length for efficient packing, and the model is trained using packed sequences. Additionally, the model is evaluated similarly using packed sequences during testing.\n",
        "\n",
        "5. **Evaluation and Analysis**:\n",
        "   - **Feedforward Neural Network**: Evaluation of the feedforward network typically involves computing metrics such as accuracy and possibly a confusion matrix to assess its performance.\n",
        "   - **Bidirectional LSTM**: Evaluation of the Bidirectional LSTM includes similar metrics but may also involve analyzing correctly and incorrectly classified examples to gain insights into the model's behavior, especially regarding contextual understanding.\n",
        "\n",
        "In summary, while both approaches aim to perform sentiment analysis on textual data, they differ significantly in their underlying architectures and mechanisms for handling sequential data. The Bidirectional LSTM model offers advantages in capturing contextual information, which is crucial for tasks like sentiment analysis, where the meaning of a word can depend heavily on its context within a sentence.\n"
      ],
      "metadata": {
        "id": "tK3RC-dr8S2A"
      }
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "0.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}